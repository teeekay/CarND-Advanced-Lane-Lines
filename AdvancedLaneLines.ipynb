{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import scipy.signal\n",
    "from IPython.display import HTML\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code Cell 1 - Wrapper function `camera_undistort()` to remove intrinsic distortion in Dashcam camera \n",
    "(as measured in Camera Calibration notebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "information needed for undistort\n",
    "'''\n",
    "dist_pickle = pickle.load( open( \"./camera_cal/cal_dist_pickle.p\", \"rb\" ) )\n",
    "undistort_mtx = dist_pickle[\"mtx\"]\n",
    "undistort_dist = dist_pickle[\"dist\"]\n",
    "\n",
    "'''\n",
    "func: undistort\n",
    "removes intrinsic camera distortion effects\n",
    "leaves black in frame (does not crop) outside visible edges of corrrected image\n",
    "'''\n",
    "def camera_undistort(img):  \n",
    "    # Use the OpenCV undistort() function to remove distortion\n",
    "    h,  w = img.shape[:2]\n",
    "    new_mtx, roi=cv2.getOptimalNewCameraMatrix(undistort_mtx,undistort_dist,(w,h),1,(w,h))\n",
    "    undist = cv2.undistort(img, undistort_mtx, undistort_dist, None, new_mtx)\n",
    "    return undist\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code Cell 2 - Wrapper function `undistort_crop()` to remove blank sections of corrected image for display "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "undistort_src = np.float32([[59,63],\n",
    "                           [1244, 63], \n",
    "                           [1244, 673], \n",
    "                           [59, 673]])\n",
    "\n",
    "undistort_dst = np.float32([[0, 0],\n",
    "                           [1279, 0], \n",
    "                           [1279,719], \n",
    "                           [0,719]])\n",
    "def undistort_crop(img):\n",
    "    # Given src and dst points, calculate the perspective transform matrix\n",
    "    undistort_M = cv2.getPerspectiveTransform(undistort_src, undistort_dst)\n",
    "    img_size =(1280,720)\n",
    "    # Warp the image using OpenCV warpPerspective()\n",
    "    warped = cv2.warpPerspective(img, undistort_M, img_size)\n",
    "    return warped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code Cell 3 - Wrapper functions `birdseye_transform()` and `birdseye_untransform()` to switch from dashcam to overhead (planar) view  \n",
    "these also switch image aspect from 1280x720 to 720x1280"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "information needed for birdseye_transform \n",
    "'''\n",
    "birdseye_src = np.float32([[617, 450],\n",
    "                           [711, 450], \n",
    "                           [988, 626], \n",
    "                           [359, 626]])\n",
    "  \n",
    "birdseye_dst = np.float32([[260, 640],\n",
    "                           [460, 640], \n",
    "                           [460,1260], \n",
    "                           [260,1260]])   \n",
    "'''\n",
    "func: birdseye_transform()\n",
    "transform image from perspective view to overhead (birdseye) view\n",
    "'''\n",
    "def birdseye_transform(img):\n",
    "    # Given src and dst points, calculate the perspective transform matrix\n",
    "    birdseye_M = cv2.getPerspectiveTransform(birdseye_src, birdseye_dst)\n",
    "    img_size = (img.shape[1],img.shape[0])\n",
    "    img_size =(720,1280)\n",
    "    # Warp the image using OpenCV warpPerspective()\n",
    "    warped = cv2.warpPerspective(img, birdseye_M, img_size)\n",
    "    return warped\n",
    "'''\n",
    "func: birdseye_untransform()\n",
    "transform image from overhead (birdseye) to perspective view view\n",
    "'''\n",
    "def birdseye_untransform(img):\n",
    "    # Given src and dst points, calculate the perspective transform matrix\n",
    "    birdseye_M_inv = cv2.getPerspectiveTransform(birdseye_dst, birdseye_src)\n",
    "    #img_size = (img.shape[1],img.shape[0])\n",
    "    img_size =(1280,720)\n",
    "    # Warp the image using OpenCV warpPerspective()\n",
    "    warped = cv2.warpPerspective(img, birdseye_M_inv, img_size)\n",
    "    return warped\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Code Cell 4 - Wrapper Functions for Sobel operations\n",
    "\n",
    "Developed sobel_grad function based partially on information found in\n",
    "http://rvsn.csail.mit.edu/Pubs/phd_ashuang_2010feb_laneestimation.pdf \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "sobel_thresh\n",
    "input: single plane image\n",
    "choice to apply sobel in x, y or both and using different derivative or filter kernel size\n",
    "'''\n",
    "X_DIR = 1\n",
    "Y_DIR = 2\n",
    "MAGNITUDE = 4+2+1\n",
    "ANGLE = 8+2+1\n",
    "\n",
    "def sobel_thresh(img, orient=X_DIR, thresh_min=0, thresh_max=255, ksize=3, deriv=1):\n",
    "    if img.ndim != 2:\n",
    "        print(\"Error in sobel_thresh: img is supposed to have 2 dimensions, but has {} dimensions\".format(img.ndim))\n",
    "        return False, np.array([0])\n",
    "    X_DIR = 1\n",
    "    Y_DIR = 2\n",
    "    MAGNITUDE = 4+2+1\n",
    "    ANGLE = 8+2+1 \n",
    "    \n",
    "        \n",
    "    # Take the derivative in x or y\n",
    "    if orient & X_DIR == X_DIR:\n",
    "        sobel = cv2.Sobel(img, cv2.CV_64F, 1*deriv, 0, ksize=ksize)\n",
    "        #3) Take the absolute value of the derivative or gradient\n",
    "        abs_sobelx = np.absolute(sobel)\n",
    "        abs_sobel = abs_sobelx\n",
    "    if orient & Y_DIR == Y_DIR:\n",
    "        sobel = cv2.Sobel(img, cv2.CV_64F, 0, 1*deriv, ksize=ksize)\n",
    "        #Take the absolute value of the derivative or gradient\n",
    "        abs_sobely = np.absolute(sobel)\n",
    "        abs_sobel = abs_sobely\n",
    "\n",
    "    #calculate magnitude or angle and scale output to range 0-255\n",
    "    if orient == MAGNITUDE:\n",
    "        magnitude = np.sqrt(abs_sobelx**2 + abs_sobely**2)\n",
    "        # 4) Scale to 8-bit (0 - 255) then convert to type = np.uint8\n",
    "        scaled_sobel = np.uint8(255*magnitude/np.max(magnitude))\n",
    "    elif orient == ANGLE:\n",
    "        angle = np.arctan2(abs_sobely, abs_sobelx)\n",
    "        # scale to pi/2 = 255 - the direction is important\n",
    "        print(\"Min Angular value is {} and Max value is {}.\".format(np.min(angle/np.pi),np.max(angle/np.pi)))\n",
    "        scaled_sobel = np.uint8(255*angle/(np.pi/2))\n",
    "    else:      \n",
    "        # 4) Scale to 8-bit (0 - 255) then convert to type = np.uint8\n",
    "        scaled_sobel = np.uint8(255*abs_sobel/np.max(abs_sobel))\n",
    "        \n",
    "    # 5) Create a mask of 1's where the scaled gradient magnitude \n",
    "    # is > thresh_min and < thresh_max   \n",
    "    sbinary = np.zeros_like(scaled_sobel)\n",
    "    sbinary[(scaled_sobel >= thresh_min) & (scaled_sobel <= thresh_max)] = 1\n",
    "    \n",
    "    # 6) Return this mask as your binary_output image\n",
    "    return True, sbinary\n",
    "\n",
    "'''\n",
    "experimental function to find lines\n",
    "second derivative down lines (generally in y direction should be close to zero)\n",
    "\n",
    "'''\n",
    "def sobel_grad(img, ksize=(5,3), deriv=(1,2)):\n",
    "    sobelx = cv2.Sobel(img, cv2.CV_64F, deriv[0], 0, ksize=ksize[0])\n",
    "    sobely = cv2.Sobel(img, cv2.CV_64F, 0, deriv[1], ksize=ksize[1])\n",
    "    magnitude = np.sqrt(sobelx**2 + sobely**2)\n",
    "    angle = np.arctan2(sobely, sobelx)\n",
    "    sobel = np.dstack((np.zeros_like(sobelx),magnitude, angle))\n",
    "    return sobel\n",
    "#    return magnitude\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code Cell 5 - Custom kernels for use in convolutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "custom line detection kernels built to find lines that are 4 to 6 pixels wide and generally vertical\n",
    "kernel1 to remove noise smaller than 3*3\n",
    "kernel2 for 10 pixel wide solid line\n",
    "'''\n",
    "kernel1 = np.array([[1,1,1],[1,1,1],[1,1,1]])\n",
    "\n",
    "kernel2 = np.array([[0,-1,1,0,0,0,0,0,0,0,0,1,-1,0],\n",
    "                    [0,-1,1,0,0,0,0,0,0,0,0,1,-1,0],\n",
    "                    [0,-1,1,0,0,0,0,0,0,0,0,1,-1,0],\n",
    "                    [0,-1,1,0,0,0,0,0,0,0,0,1,-1,0],\n",
    "                    [0,-1,1,0,0,0,0,0,0,0,0,1,-1,0]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code Cell 6 - Function `line_pipeline` to apply thresholds using color channels and sobels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def line_pipeline(img, convolve=False):\n",
    "    #remove camera distortion\n",
    "    tru_img = camera_undistort(img)\n",
    "    #switch to overhead view\n",
    "    birdseye_img = birdseye_transform(tru_img)\n",
    "    \n",
    "    # pull out channels to be used for thresholding\n",
    "    b_img = birdseye_img[:,:,0]\n",
    "    g_img = birdseye_img[:,:,1]\n",
    "    r_img = birdseye_img[:,:,2]\n",
    "    hsv_img = cv2.cvtColor(birdseye_img, cv2.COLOR_BGR2HSV)\n",
    "    h_img = hsv_img[:,:,0]\n",
    "    s_img = hsv_img[:,:,1]\n",
    "    v_img = hsv_img[:,:,2]\n",
    "    HLS_img = cv2.cvtColor(birdseye_img, cv2.COLOR_BGR2HLS)\n",
    "    H_img = HLS_img[:,:,0]\n",
    "    L_img = HLS_img[:,:,1]\n",
    "    S_img = HLS_img[:,:,2]  \n",
    "    YCrCb_img = cv2.cvtColor(birdseye_img,cv2.COLOR_BGR2YCR_CB)\n",
    "    Y_img = YCrCb_img[:,:,0]\n",
    "    CR_img = YCrCb_img[:,:,1]\n",
    "    CB_img = YCrCb_img[:,:,2] \n",
    "    \n",
    "    sobel_inp  = np.copy(v_img)\n",
    "    \n",
    "    sgrad_img = sobel_grad(sobel_inp)\n",
    "    sobel_mag = sgrad_img[:,:,1]\n",
    "    sobel_thresh = np.zeros_like(sobel_inp, dtype=np.uint8)\n",
    "    sobel_thresh[sobel_mag>1750] = 1\n",
    "    #thresh_mag_and_h_and_L = np.zeros_like(sobel_mag)\n",
    "    \n",
    "    rc = np.zeros_like(sobel_inp, dtype=np.uint8)\n",
    "    \n",
    "    rc[ (sobel_thresh>0)| \n",
    "       (v_img>220) | \n",
    "       ((h_img>=19) &(h_img<=24)) |\n",
    "       ((H_img>17)&(H_img<45)&(L_img>140)&(L_img<180)&(S_img>80))| \n",
    "       (L_img > 220) |\n",
    "       (Y_img>200)|\n",
    "       ((CR_img>142)&(CR_img<170))| \n",
    "       ((CB_img>30)&(CB_img<110)) |\n",
    "       ((r_img>225)&(g_img>180)&(b_img<170))]=1 \n",
    "       \n",
    "    # Do a little noise removal\n",
    "    conv = scipy.signal.convolve2d(rc, kernel1, mode='same')\n",
    "    rc = np.zeros_like(conv, dtype=np.uint8)\n",
    "    rc[conv>6]=1\n",
    "    \n",
    "    # get rid of shadows and other pathches with a convolution\n",
    "    if convolve == True:\n",
    "        #print(\"using convolution\", end = '')\n",
    "        rc = scipy.signal.convolve2d(rc, kernel2, mode='same')\n",
    "        conv = np.zeros_like(rc, dtype=np.uint8)\n",
    "        conv[rc>0]=1\n",
    "        rc = conv\n",
    "    \n",
    "    return rc, tru_img, birdseye_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code Cell 7 - data_storage class - used to store images and data between multiple frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "started out as a place to stash an image, morphed into storage for\n",
    "data between frames\n",
    "'''\n",
    "class data_storage(): #binary_image():\n",
    "    def __init__(self):\n",
    "        self.new_image = np.array([0])\n",
    "        self.old_image = np.array([0])\n",
    "        #displacement from last image\n",
    "        self.displacement = []\n",
    "        self.frame = 0\n",
    "        self.fps = 25 #default non null value\n",
    "        # was the line detected in the last iteration?\n",
    "        self.linesdetected = False  \n",
    "        #polynomial coefficients\n",
    "        self.avg_lft_fit = np.array([0.,0.,0.])\n",
    "        self.avg_rgt_fit = np.array([0.,0.,0.])\n",
    "        self.left_fita = []\n",
    "        self.left_fitb = []\n",
    "        self.left_fitc = []\n",
    "        self.right_fita = []\n",
    "        self.right_fitb = []\n",
    "        self.right_fitc = []\n",
    "        #radius of curvature of the line in some units\n",
    "        self.curvatureL = []\n",
    "        self.curvatureR = []\n",
    "        #count of frames where generally non parallel lines collected\n",
    "        self.bad_frames = 0\n",
    "        #distance in meters of vehicle center from the line\n",
    "        self.line_base_pos = None \n",
    "        #difference in fit coefficients between last and new fits\n",
    "        self.diffs = np.array([0,0,0], dtype='float') \n",
    "    def add_new_image(self, bin_img):\n",
    "#        print(\"Adding new image to storage.\")\n",
    "        self.old_image = np.copy(self.new_image)\n",
    "        self.new_image = np.copy(bin_img)\n",
    "    def add_fps(self, fps):\n",
    "        self.fps = fps\n",
    "    def add_displacement(self, displacement):\n",
    "        self.displacement = self.displacement[-3:]\n",
    "        self.displacement.append(displacement)\n",
    "    def add_curvature(self, curvatureL, curvatureR):\n",
    "        self.curvatureL = self.curvatureL[-7:]\n",
    "        self.curvatureL.append(curvatureL)\n",
    "        self.curvatureR = self.curvatureR[-7:]\n",
    "        self.curvatureR.append(curvatureR)\n",
    "    def set_lines_detected(self, detected):\n",
    "        #should be a boolean\n",
    "        self.linesdetected = detected\n",
    "    def save_fitx(self, left_fitx,right_fitx):\n",
    "        self.left_fitx = left_fitx\n",
    "        self.right_fitx = right_fitx\n",
    "        self.bad_frames = 0\n",
    "    def save_fit(self, left_fit, right_fit):\n",
    "        self.left_fita = self.left_fita[-3:]\n",
    "        self.left_fitb = self.left_fitb[-3:]\n",
    "        self.left_fitc = self.left_fitc[-3:]\n",
    "        self.left_fita.append(left_fit[0])\n",
    "        self.left_fitb.append(left_fit[1])\n",
    "        self.left_fitc.append(left_fit[2])\n",
    "        self.right_fita = self.right_fita[-3:]\n",
    "        self.right_fitb = self.right_fitb[-3:]\n",
    "        self.right_fitc = self.right_fitc[-3:]\n",
    "        self.right_fita.append(right_fit[0])\n",
    "        self.right_fitb.append(right_fit[1])\n",
    "        self.right_fitc.append(right_fit[2])\n",
    "        self.avg_lft_fit[0]= np.average(self.left_fita)\n",
    "        self.avg_lft_fit[1]= np.average(self.left_fitb)\n",
    "        self.avg_lft_fit[2]= np.average(self.left_fitc)\n",
    "        self.avg_rgt_fit[0]= np.average(self.right_fita)\n",
    "        self.avg_rgt_fit[1]= np.average(self.right_fitb)\n",
    "        self.avg_rgt_fit[2]= np.average(self.right_fitc)\n",
    "        return(self.avg_lft_fit, self.avg_rgt_fit)\n",
    "            \n",
    "    def increment_bad_frames(self):\n",
    "        self.bad_frames += 1\n",
    "        self.linesdetected = False \n",
    "        return(int(self.bad_frames))\n",
    "    def set_frame(self, frame):\n",
    "        self.frame=frame\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code Cell  8 - feed_the_beast function - the main image processing pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def feed_the_beast(orig_imgBGR, data_store, convolve=False):\n",
    "    orig_imgRGB = cv2.cvtColor(orig_imgBGR, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    threshd_bin, truimgBGR, brdseyeBGR = line_pipeline(orig_imgBGR, convolve=convolve) \n",
    "\n",
    "    data_store.add_new_image(threshd_bin)\n",
    "    \n",
    "    speed = estimate_speed(data_store)\n",
    "    \n",
    "    #find_center_line(threshd_bin)\n",
    "       \n",
    "    blank = np.zeros_like(threshd_bin, dtype=np.uint8)\n",
    "    det = np.dstack((blank,threshd_bin,blank))*255\n",
    "    \n",
    "    truimgRGB = cv2.cvtColor(truimgBGR, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    small_brdseyeBGR = cv2.resize(brdseyeBGR,None,fx=0.25, fy=0.25, interpolation = cv2.INTER_AREA)\n",
    "    small_brdseyeRGB = cv2.cvtColor(small_brdseyeBGR, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    small_det = cv2.resize(det, None, fx=0.25, fy=0.25, interpolation = cv2.INTER_AREA)\n",
    "\n",
    "#    blank = np.zeros_like(small_det)\n",
    "#    small_det = np.dstack((blank,small_det,blank))*255\n",
    "        \n",
    "    new_warp, line_fit, curve_radii, offcenter  = find_lines(data_store)\n",
    "    \n",
    "    truimgpluslaneRGB = cv2.addWeighted(truimgRGB, 1, new_warp, 0.3, 0)  \n",
    "    croptruimgpluslaneRGB = undistort_crop(truimgpluslaneRGB)\n",
    "    \n",
    "    curvature = (sum(data_store.curvatureL)+sum(data_store.curvatureR))/(len(data_store.curvatureR)+len(data_store.curvatureL)+0.01)\n",
    "    \n",
    "    small_line_fit = cv2.resize(line_fit,None,fx=0.25, fy=0.25, interpolation = cv2.INTER_AREA)\n",
    "\n",
    "    croptruimgpluslaneRGB[10:330,679:859,:] = small_brdseyeRGB\n",
    "    croptruimgpluslaneRGB[10:330,879:1059,:] = small_det\n",
    "    croptruimgpluslaneRGB[10:330,1079:1259,:] = small_line_fit\n",
    "    cv2.putText(croptruimgpluslaneRGB, \"Birdseye\", (720,25), cv2.FONT_HERSHEY_SIMPLEX,0.75,(100,255,255),1,cv2.LINE_AA)\n",
    "    cv2.putText(croptruimgpluslaneRGB, \"Thresholds of\", (905,20), cv2.FONT_HERSHEY_SIMPLEX,0.5,(100,255,255),1,cv2.LINE_AA)\n",
    "    cv2.putText(croptruimgpluslaneRGB, \"Sobel & Color Chans\", (885,35), cv2.FONT_HERSHEY_SIMPLEX,0.5,(100,255,255),1,cv2.LINE_AA)\n",
    "    cv2.putText(croptruimgpluslaneRGB, \"Line Fit\", (1120,25), cv2.FONT_HERSHEY_SIMPLEX,0.75,(100,255,255),1,cv2.LINE_AA)\n",
    "    cv2.putText(croptruimgpluslaneRGB, \"Curve  Radius: {0:5,.0f} m\".format(curvature), (40,30), cv2.FONT_HERSHEY_SIMPLEX,1,(255,255,255),1,cv2.LINE_AA)\n",
    "    cv2.putText(croptruimgpluslaneRGB, \"Left   A:{0:.6f} B:{1:.5f} C:{2:3.0f}\".format(data_store.avg_lft_fit[0],\n",
    "                                                                                      data_store.avg_lft_fit[1],\n",
    "                                                                                      data_store.avg_lft_fit[2]\n",
    "                                                                                     ), (40,150), cv2.FONT_HERSHEY_SIMPLEX,0.8,(255,255,255),1,cv2.LINE_AA)\n",
    "    cv2.putText(croptruimgpluslaneRGB, \"Right  A:{0:.6f} B:{1:.5f} C:{2:3.0f}\".format(data_store.avg_rgt_fit[0],\n",
    "                                                                                      data_store.avg_rgt_fit[1],\n",
    "                                                                                      data_store.avg_rgt_fit[2]\n",
    "                                                                                     ), (40,180), cv2.FONT_HERSHEY_SIMPLEX,0.8,(255,255,255),1,cv2.LINE_AA)\n",
    "    cv2.putText(croptruimgpluslaneRGB, \"Frame:{0:5d} Timestamp:{1:3.03f}\".format(data_store.frame, (data_store.frame/data_store.fps)),\n",
    "                                                                                    (40,210), cv2.FONT_HERSHEY_SIMPLEX,0.8,(255,255,255),1,cv2.LINE_AA)\n",
    "\n",
    "\n",
    "#    cv2.putText(croptruimgpluslaneRGB, \"Left  Radius: {0:5,.0f} m\".format(curve_radii[0]), (40,70), cv2.FONT_HERSHEY_SIMPLEX,1,(255,255,255),1,cv2.LINE_AA)\n",
    "#    cv2.putText(croptruimgpluslaneRGB, \"Right Radius: {0:5,.0f} m\".format(curve_radii[1]), (40,110), cv2.FONT_HERSHEY_SIMPLEX,1,(255,255,255),1,cv2.LINE_AA)\n",
    "    cv2.putText(croptruimgpluslaneRGB, \"Off Lane Center: {0:2.2f} m\".format(offcenter), (40,70), cv2.FONT_HERSHEY_SIMPLEX,1,(255,255,255),1,cv2.LINE_AA)\n",
    "    cv2.putText(croptruimgpluslaneRGB, \"Speed: {0:3.0f} km/hr\".format(speed), (40,110), cv2.FONT_HERSHEY_SIMPLEX,1,(255,255,255),1,cv2.LINE_AA)\n",
    "    \n",
    "    return croptruimgpluslaneRGB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code Cell 9 - find_lines function - uses binary thresholded images to generate polyfitted line markers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def find_lines(data_store):\n",
    "    binary_warped = np.copy(data_store.new_image)\n",
    "    #flip the image so that polynomial coefficient 2 represents line location at the front of the car (not on the horizon)\n",
    "    binary_warped = cv2.flip(binary_warped,flipCode=0)\n",
    "    warp_zero = np.zeros_like(binary_warped).astype(np.uint8)\n",
    "    color_warp = np.dstack((warp_zero, warp_zero, warp_zero)) \n",
    "\n",
    "# Assuming you have created a warped binary image called \"binary_warped\"\n",
    "# Take a histogram of the bottom half of the image\n",
    "    '''\n",
    "    The birdseye image is 720 wide by 1280 high\n",
    "    the center of the camera and car is at 720/2 = 360\n",
    "    lane lines are expected to be at about 260 and 460 \n",
    "            about 100 pixel offsets from center\n",
    "    take a histogram of top 1/3 of image (since it's flipped) from x = 200 to 520\n",
    "    to look for lane lines\n",
    "    '''  \n",
    "\n",
    "    \n",
    "    left_edge = 200\n",
    "    right_edge = 520\n",
    "    \n",
    "    \n",
    "    # Create an output image to draw on and  visualize the result\n",
    "    out_img1 = np.dstack((binary_warped, binary_warped, binary_warped))*255\n",
    "    window_img = np.zeros_like(out_img1)  \n",
    "    # Identify the x and y positions of all nonzero pixels in the image\n",
    "    nonzero = binary_warped[0:int(binary_warped.shape[0]*2/3),:].nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "    # Set the width of the windows +/- margin\n",
    "    margin = 40\n",
    "    # Set minimum number of pixels found to recenter window\n",
    "    minpix = 45\n",
    "    # Create empty lists to receive left and right lane pixel indices\n",
    "    left_lane_inds = []\n",
    "    right_lane_inds = []\n",
    "  \n",
    "    if data_store.linesdetected == False: # or (data_store.frame%10) == 0:\n",
    "\n",
    "        histogram = np.sum(binary_warped[:binary_warped.shape[0]//3,left_edge:right_edge], axis=0)     \n",
    "\n",
    "        midpoint = np.int(histogram.shape[0]/2)\n",
    "\n",
    "        # Find the peak of the left and right halves of the histogram\n",
    "        # These will be the starting point for the left and right lines\n",
    "        leftx_base = np.argmax(histogram[:midpoint]) + left_edge\n",
    "        #    print(\"left lane at {}\".format(leftx_base))\n",
    "        rightx_base = np.argmax(histogram[midpoint:]) + midpoint + left_edge\n",
    "        #    print(\"right lane at {}\".format(rightx_base))    \n",
    "    \n",
    "        # Choose the number of sliding windows\n",
    "        nwindows = 10 # - need to make so that \n",
    "        # Set height of windows\n",
    "        #window_height = np.int(binary_warped.shape[0]/nwindows)\n",
    "        #reduce height looking for lanes to get more confidant result\n",
    "        window_height = np.int(binary_warped.shape[0]*(2/3)/nwindows)\n",
    "        # Current positions to be updated for each window\n",
    "        leftx_current = leftx_base\n",
    "        rightx_current = rightx_base\n",
    "        \n",
    "        # Step through the windows one by one\n",
    "        for window in range(nwindows):\n",
    "            # Identify window boundaries in x and y (and right and left)\n",
    "            #win_y_low = binary_warped.shape[0] - (window+1)*window_height\n",
    "            #win_y_high = binary_warped.shape[0] - window*window_height\n",
    "            win_y_low = window*window_height\n",
    "            win_y_high = (window+1)*window_height\n",
    "            win_xleft_low = leftx_current - margin\n",
    "            win_xleft_high = leftx_current + margin\n",
    "            win_xright_low = rightx_current - margin\n",
    "            win_xright_high = rightx_current + margin\n",
    "            # Draw the windows on the visualization image\n",
    "            cv2.rectangle(out_img1,(win_xleft_low,win_y_low),(win_xleft_high,win_y_high),(0,255,0), 2) \n",
    "            cv2.rectangle(out_img1,(win_xright_low,win_y_low),(win_xright_high,win_y_high),(0,255,0), 2) \n",
    "            # Identify the nonzero pixels in x and y within the window\n",
    "            good_left_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & (nonzerox >= win_xleft_low) & (nonzerox < win_xleft_high)).nonzero()[0]\n",
    "            good_right_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & (nonzerox >= win_xright_low) & (nonzerox < win_xright_high)).nonzero()[0]\n",
    "            # Append these indices to the lists\n",
    "            left_lane_inds.append(good_left_inds)\n",
    "            right_lane_inds.append(good_right_inds)\n",
    "            # If you found > minpix pixels, recenter next window on their mean position\n",
    "            if len(good_left_inds) > minpix:\n",
    "                leftx_current = np.int(np.mean(nonzerox[good_left_inds]))\n",
    "            if len(good_right_inds) > minpix:        \n",
    "                rightx_current = np.int(np.mean(nonzerox[good_right_inds]))    \n",
    "       \n",
    "        # Concatenate the arrays of indices\n",
    "        left_lane_inds = np.concatenate(left_lane_inds)\n",
    "        right_lane_inds = np.concatenate(right_lane_inds)\n",
    "        data_store.set_lines_detected(True)\n",
    "    \n",
    "    else: #search from last detectd  line\n",
    "        left_fit = data_store.avg_lft_fit\n",
    "        right_fit = data_store.avg_rgt_fit\n",
    "        left_lane_inds = ((nonzerox > (left_fit[0]*(nonzeroy**2) + left_fit[1]*nonzeroy + left_fit[2] - margin)) &\n",
    "                           (nonzerox < (left_fit[0]*(nonzeroy**2) + left_fit[1]*nonzeroy + left_fit[2] + margin))) \n",
    "        right_lane_inds = ((nonzerox > (right_fit[0]*(nonzeroy**2) + right_fit[1]*nonzeroy + right_fit[2] - margin)) &\n",
    "                           (nonzerox < (right_fit[0]*(nonzeroy**2) + right_fit[1]*nonzeroy + right_fit[2] + margin)))  \n",
    "        \n",
    "    # Extract left and right line pixel positions\n",
    "    leftx = nonzerox[left_lane_inds]\n",
    "    lefty = nonzeroy[left_lane_inds] \n",
    "    rightx = nonzerox[right_lane_inds]\n",
    "    righty = nonzeroy[right_lane_inds] \n",
    "    \n",
    "    # Fit a second order polynomial to each\n",
    "    if (len(lefty)>0) & (len(leftx)>0) & (len(rightx)>0) & (len(righty)>0):\n",
    "        \n",
    "        old_left_fit = data_store.avg_lft_fit\n",
    "        old_right_fit = data_store.avg_rgt_fit\n",
    "        \n",
    "        left_fit = np.polyfit(lefty, leftx, 2)\n",
    "        right_fit = np.polyfit(righty, rightx, 2)\n",
    "        #left_fit, right_fit = data_store.save_fit(left_fit,right_fit)\n",
    "        # check if seems right at front of car (1260)\n",
    "        #print(\"fnd lft_fita={0:3.5f}, lft_fitb={1:3.5f}, lft_fitc={2:3.5f}\".format(left_fit[0],left_fit[1],left_fit[2]), end ='')\n",
    "        #print(\"fnd rht_fita={0:3.5f}, rht_fitb={1:3.5f}, rht_fitc={2:3.5f}\".format(right_fit[0],right_fit[1],right_fit[2]))\n",
    "        \n",
    "                \n",
    "        if left_fit[2] > 220 and left_fit[2] < 300 and right_fit[2]-left_fit[2]>170 and right_fit[2]-left_fit[2]<230:\n",
    "            #evrything looks ok at one end\n",
    "            left_fit, right_fit = data_store.save_fit(left_fit,right_fit)\n",
    "        elif left_fit[2] > 220 and left_fit[2] < 300 and (right_fit[2]-left_fit[2]<=170 or right_fit[2]-left_fit[2]>=230):\n",
    "            right_fit[2] = left_fit[2] + 200\n",
    "            right_fit[1] = left_fit[1]\n",
    "            right_fit[0] = left_fit[0]\n",
    "            left_fit, right_fit = data_store.save_fit(left_fit,right_fit)\n",
    "        elif (left_fit[2] <= 220 or left_fit[2] >= 300) and (right_fit[2] > 420 and right_fit[2] < 500):\n",
    "            left_fit[2] = right_fit[2] - 200\n",
    "            left_fit[1] = right_fit[1]\n",
    "            left_fit[1] = right_fit[1]\n",
    "            left_fit, right_fit = data_store.save_fit(left_fit,right_fit)\n",
    "        else:\n",
    "            left_fit = old_left_fit\n",
    "            right_fit = old_right_fit\n",
    "            left_fit, right_fit = data_store.save_fit(left_fit,right_fit)\n",
    "            data_store.increment_bad_frames()\n",
    "        #print(\"Fix lft_fita={0:3.5f}, lft_fitb={1:3.5f}, lft_fitc={2:3.5f}\".format(left_fit[0],left_fit[1],left_fit[2]), end='')\n",
    "        #print(\"Fix rht_fita={0:3.5f}, rht_fitb={1:3.5f}, rht_fitc={2:3.5f}\".format(right_fit[0],right_fit[1],right_fit[2]))\n",
    "        \n",
    "        # Generate x and y values for plotting\n",
    "        \n",
    "        ploty = np.linspace(0, int(binary_warped.shape[0]*2/3)-1, int(binary_warped.shape[0]*2/3) )\n",
    "      \n",
    "        \n",
    "        left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "        right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    " \n",
    "        #print()\n",
    "        lane_center = (left_fitx[20] + right_fitx[20])/2\n",
    "        #calculate displacement of center of lane from center of the image\n",
    "        off_lane_center = (lane_center - 360)*3.7/200\n",
    "\n",
    "        lane_width_check = np.average(right_fitx[0:100]-left_fitx[0:100])\n",
    "        #print(\"Detected Lane width of {0:2.1f} pixels, which is off car center by {1:1.2f}m\".format(lane_width_check, off_lane_center))\n",
    "        #print(\"lane_width_check is {} pixels\".format(lane_width_check))\n",
    "        #if lane_width_check < 185 or lane_width_check > 230:\n",
    "        #    #discard - use last good measurement\n",
    "        #    left_fitx = data_store.left_fitx\n",
    "        #    right_fitx = data_store.right_fitx\n",
    "        #    frame = int(data_store.frame)\n",
    "        #    bad_frames = int(data_store.increment_bad_frames())\n",
    "        #    print(\"frame:{0:4d} rejected lane width {1:3.0f}- probably non parallel {2:2d} consecutive frames\".format(frame, lane_width_check, bad_frames))\n",
    "        #else:\n",
    "        data_store.save_fitx(left_fitx,right_fitx)\n",
    "              \n",
    "        radii = find_radius( left_fitx, right_fitx, ploty )\n",
    "        data_store.add_curvature(radii[0],radii[1])\n",
    "                \n",
    "        out_img1[nonzeroy[left_lane_inds], nonzerox[left_lane_inds]] = [255, 0, 0]\n",
    "        out_img1[nonzeroy[right_lane_inds], nonzerox[right_lane_inds]] = [0, 0, 255]\n",
    "                  \n",
    "        # Generate a polygon to illustrate the search window area\n",
    "        # And recast the x and y points into usable format for cv2.fillPoly()\n",
    "        left_line_window1 = np.array([np.transpose(np.vstack([left_fitx-margin, ploty]))])\n",
    "        left_line_window2 = np.array([np.flipud(np.transpose(np.vstack([left_fitx+margin, ploty])))])\n",
    "        left_line_pts = np.hstack((left_line_window1, left_line_window2))\n",
    "        right_line_window1 = np.array([np.transpose(np.vstack([right_fitx-margin, ploty]))])\n",
    "        right_line_window2 = np.array([np.flipud(np.transpose(np.vstack([right_fitx+margin, ploty])))])\n",
    "        right_line_pts = np.hstack((right_line_window1, right_line_window2))\n",
    "        \n",
    "        # Draw the lane onto the warped blank image\n",
    "        cv2.fillPoly(window_img, np.int_([left_line_pts]), (0,255, 0))\n",
    "        cv2.fillPoly(window_img, np.int_([right_line_pts]), (0,255, 0))\n",
    "        result = cv2.addWeighted(out_img1, 1, window_img, 0.5, 0)\n",
    "            \n",
    "        # Recast the x and y points into usable format for cv2.fillPoly()\n",
    "        pts_left = np.array([np.transpose(np.vstack([left_fitx, ploty]))])\n",
    "        pts_right = np.array([np.flipud(np.transpose(np.vstack([right_fitx, ploty])))])\n",
    "        pts = np.hstack((pts_left, pts_right))\n",
    "        \n",
    "        #cv2.minEnclosingCircle(pts_left)\n",
    "    \n",
    "        # Draw the lane onto the warped blank image\n",
    "        cv2.fillPoly(color_warp, np.int_([pts]), (0,255, 0))\n",
    "        color_warp = cv2.flip(color_warp, flipCode=0)\n",
    "        result = cv2.flip(result, flipCode=0)\n",
    "        \n",
    "    else:\n",
    "        result = color_warp # which will be blank\n",
    "        radii = (0.,0.)\n",
    "        off_lane_center = 0\n",
    "        \n",
    "    newwarp = birdseye_untransform(color_warp)\n",
    "    return newwarp, result, radii, off_lane_center\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code cell 10 - estimate_speed function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    "thoughts:\n",
    "could try subtracting old image from new image and look for vertical size of positive blobs\n",
    "or could convolve old with new and find maximum response (movement)  possibly try in smaller window to make faster\n",
    "test1: try convolution /correlation - didn't achieve what I wanted\n",
    "test2: Try least squares difference between section of new image slid over old image - works ok\n",
    "\n",
    "'''\n",
    "def estimate_speed(data_store, debug=False):\n",
    "#    print(\"estimating speed\")\n",
    "    old_bin = np.copy(data_store.old_image)\n",
    "    new_bin = np.copy(data_store.new_image)\n",
    "    \n",
    "    if np.ndim(old_bin) < 2:\n",
    "        # no stored data\n",
    "        print(\"no stored image - returning\")\n",
    "        speed = 0\n",
    "        return speed\n",
    "    else:\n",
    "        #take a slice of road with lane lines on it in new binary image\n",
    "        #then take a histogram of the pixels in it vertically, and flip it\n",
    "        #so that the bottom of the image is now found at the start of the histogram.\n",
    "        new_bin = np.flipud(np.sum(new_bin[1000:1200,200:520],axis=1))\n",
    "        #take a taller slice of road with lane lines on it from last binary image\n",
    "        # this should have the section of road see at the bottom of the new image\n",
    "        # slightly higher up the image (and further along the histogram)\n",
    "        # the distance for the match depends on the speed of the car and the fps of the video\n",
    "        # but at 100 km/hr and 25 fps, we should expect about 25 pixels displacement\n",
    "        # a window of 100 should cover other scenarios - this does limit resolution of speedo\n",
    "        # to about 4 km/hr in this scenario\n",
    "        old_bin = np.flipud(np.sum(old_bin[900:1200,200:520], axis=1))\n",
    "\n",
    "        if debug == True:\n",
    "            plt.plot(new_bin)\n",
    "            plt.show()\n",
    "            plt.plot(old_bin)\n",
    "            plt.show()\n",
    "        difference = np.array([])\n",
    "        for i in range(1,100):\n",
    "            old_bin_window = old_bin[i-1:199+i]\n",
    "            ssd = ((new_bin - old_bin_window)**2).sum()\n",
    "            difference = np.append(difference, ssd)\n",
    "        displacement_pixels = ( np.argmin(difference))\n",
    "        if debug == True:\n",
    "            plt.plot(difference)\n",
    "            plt.show()\n",
    "            print(\"displacement is {0:3.1f} pixels.\".format(displacement_pixels))\n",
    "\n",
    "        data_store.add_displacement(displacement_pixels)\n",
    "        frames_used = len(data_store.displacement)\n",
    "        pixel_disp_in_muliple_frames = sum(data_store.displacement)\n",
    "        meter_disp = pixel_disp_in_muliple_frames * (3.0/90)\n",
    "        speed = meter_disp * (3600 / 1000) * (data_store.fps/frames_used)\n",
    "        return speed\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code Cell 11 - find_radius function - estimates the radii of curvature of the lane lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def find_radius( leftx, rightx, ploty):\n",
    "\n",
    "    ym_per_pix = 3.0/90 # meters per pixel in y dimension\n",
    "    xm_per_pix = 3.7/200 # meters per pixel in x dimension\n",
    "\n",
    "    #y_eval = np.max(ploty)\n",
    "    y_eval = 20\n",
    "\n",
    "    # Fit new polynomials to x,y in world space\n",
    "    left_fit_cr = np.polyfit(ploty*ym_per_pix, leftx*xm_per_pix, 2)\n",
    "    right_fit_cr = np.polyfit(ploty*ym_per_pix, rightx*xm_per_pix, 2)\n",
    "    # Calculate the new radii of curvature\n",
    "    left_curverad = ((1 + (2*left_fit_cr[0]*y_eval*ym_per_pix + left_fit_cr[1])**2)**1.5) / np.absolute(2*left_fit_cr[0])\n",
    "    right_curverad = ((1 + (2*right_fit_cr[0]*y_eval*ym_per_pix + right_fit_cr[1])**2)**1.5) / np.absolute(2*right_fit_cr[0])\n",
    "    # Now our radius of curvature is in meters\n",
    "\n",
    "    return (left_curverad, right_curverad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code Cell 12 - main video processing code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video opened with framecount of 1,260, dimensions (1280, 720), and speed of 25.000 fps.\n",
      "no stored image - returning\n",
      "Frames: 1257, Seconds: 50.280\n",
      "Closed video after getting empty frame 1258\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture('./project_video.mp4')\n",
    "\n",
    "fps = float(cap.get(cv2.CAP_PROP_FPS))\n",
    "framewidth = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frameheight = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "framecount = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "print(\"Video opened with framecount of {:4,d}, dimensions ({:4d},{:4d}), and speed of {:3.03f} fps.\"\n",
    "     .format(framecount, framewidth, frameheight, fps))\n",
    "\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc(*\"H264\")\n",
    "\n",
    "out = cv2.VideoWriter('./project_video_output_a.mp4', fourcc, fps, (framewidth, frameheight))\n",
    "\n",
    "frames = 0\n",
    "#initialize place to keep old and new binary thresholded images\n",
    "data_stored = data_storage()\n",
    "data_stored.add_fps(fps)\n",
    "\n",
    "while(cap.isOpened()):\n",
    "    frames += 1\n",
    "    data_stored.set_frame(frames)\n",
    "    \n",
    "    #uncomment for early stop\n",
    "    #framecount = 50\n",
    "    \n",
    "    if frames > framecount:\n",
    "        print(\"\\nClosed video after passing expected framecount of {}\".format(frames-1))\n",
    "        break\n",
    "    ret, image1 = cap.read()\n",
    "    if ret == True: \n",
    "        image1BGR = cv2.cvtColor(image1, cv2.COLOR_RGB2BGR)\n",
    "        output = feed_the_beast(image1BGR, data_stored, convolve=True)\n",
    "        msecs = float(cap.get(cv2.CAP_PROP_POS_MSEC))\n",
    "        out.write(output)\n",
    "        print(\"Frames: {0:02d}, Seconds: {1:03.03f}\".format(frames, frames/fps), end='\\r')\n",
    "    else:\n",
    "        print(\"\\nClosed video after getting empty frame {}\".format(frames))\n",
    "        break\n",
    "       \n",
    "cap.release()\n",
    "out.release()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code Cell 13 - for inline display of video output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#HTML(\"\"\"\n",
    "#<video width=\"640\" height=\"360\" controls>\n",
    "#  <source src=\"{0}\">\n",
    "#</video>\n",
    "#\"\"\".format(\"./project_video_output.mp4\"))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
